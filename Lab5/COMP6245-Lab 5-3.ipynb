{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumDataPerClass = 200\n",
    "# Two-class problem, distinct means, equal covariance matrices\n",
    "#\n",
    "m1 = [[0, 3]]\n",
    "m2 = [[3, 2.5]]\n",
    "C = [[2, 1], [1, 2]]\n",
    "# Set up the data by generating isotropic Guassians and\n",
    "# rotating them accordingly\n",
    "#\n",
    "A = np.linalg.cholesky(C)\n",
    "U1 = np.random.randn(NumDataPerClass,2)\n",
    "X1 = U1 @ A.T + m1\n",
    "U2 = np.random.randn(NumDataPerClass,2)\n",
    "X2 = U2 @ A.T + m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X1, X2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelPos = np.ones(NumDataPerClass)\n",
    "labelNeg = 0 * np.ones(NumDataPerClass)\n",
    "y = np.concatenate((labelPos, labelNeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2) (200,) (200, 2) (200,)\n"
     ]
    }
   ],
   "source": [
    "rIndex = np.random.permutation(2*NumDataPerClass)\n",
    "Xr = X[rIndex,]\n",
    "yr = y[rIndex]\n",
    "\n",
    "# Training and test sets (half half)\n",
    "#\n",
    "xtrain = Xr[0:NumDataPerClass]\n",
    "ytrain = yr[0:NumDataPerClass]\n",
    "xtest = Xr[NumDataPerClass:2*NumDataPerClass]\n",
    "ytest = yr[NumDataPerClass:2*NumDataPerClass]\n",
    "print(xtrain.shape, ytrain.shape, xtest.shape, ytest.shape)\n",
    "\n",
    "Ntrain = NumDataPerClass;\n",
    "Ntest = NumDataPerClass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis(x=None, data=None, cov=None):\n",
    "    \"\"\"Compute the Mahalanobis Distance between each row of x and the data  \n",
    "    x    : vector or matrix of data with, say, p columns.\n",
    "    data : ndarray of the distribution from which Mahalanobis distance of each observation of x is to be computed.\n",
    "    cov  : covariance matrix (p x p) of the distribution. If None, will be computed from data.\n",
    "    \"\"\"\n",
    "    x_minus_mu = x - np.mean(data)\n",
    "    if not cov:\n",
    "        cov = np.cov(data.T)\n",
    "    inv_covmat = sp.linalg.inv(cov)\n",
    "    left_term = np.dot(x_minus_mu, inv_covmat)\n",
    "    mahal = np.dot(left_term, x_minus_mu.T)\n",
    "    return mahal.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pred  true\n",
      "0      1   1.0\n",
      "1      1   1.0\n",
      "2      1   1.0\n",
      "3      0   0.0\n",
      "4      1   1.0\n",
      "5      1   0.0\n",
      "6      1   1.0\n",
      "7      0   1.0\n",
      "8      1   1.0\n",
      "9      1   0.0\n",
      "10     0   0.0\n",
      "11     1   0.0\n",
      "12     1   0.0\n",
      "13     1   1.0\n",
      "14     1   1.0\n",
      "15     1   1.0\n",
      "16     1   1.0\n",
      "17     1   1.0\n",
      "18     1   1.0\n",
      "19     1   1.0\n",
      "20     0   0.0\n",
      "21     0   0.0\n",
      "22     0   0.0\n",
      "23     0   0.0\n",
      "24     1   0.0\n",
      "25     1   1.0\n",
      "26     1   1.0\n",
      "27     1   0.0\n",
      "28     1   1.0\n",
      "29     1   0.0\n",
      "30     0   0.0\n",
      "31     0   0.0\n",
      "32     1   1.0\n",
      "33     1   0.0\n",
      "34     0   0.0\n",
      "35     1   1.0\n",
      "36     1   1.0\n",
      "37     0   0.0\n",
      "38     1   1.0\n",
      "39     1   1.0\n",
      "40     1   1.0\n",
      "41     1   1.0\n",
      "42     0   0.0\n",
      "43     0   0.0\n",
      "44     0   0.0\n",
      "45     1   1.0\n",
      "46     1   0.0\n",
      "47     0   0.0\n",
      "48     1   1.0\n",
      "49     0   0.0\n"
     ]
    }
   ],
   "source": [
    "class MahalanobisBinaryClassifier():\n",
    "    def __init__(self, xtrain, ytrain):\n",
    "        self.xtrain_pos = xtrain[ytrain == 1, :]\n",
    "        self.xtrain_neg = xtrain[ytrain == 0, :]\n",
    "\n",
    "    def predict_proba(self, xtest):\n",
    "        pos_neg_dists = [(p,n) for p, n in zip(mahalanobis(xtest, self.xtrain_pos), mahalanobis(xtest, self.xtrain_neg))]\n",
    "        return np.array([(1-n/(p+n), 1-p/(p+n)) for p,n in pos_neg_dists])\n",
    "\n",
    "    def predict(self, xtest):\n",
    "        return np.array([np.argmax(row) for row in self.predict_proba(xtest)])\n",
    "\n",
    "\n",
    "clf = MahalanobisBinaryClassifier(xtrain, ytrain)        \n",
    "pred_probs = clf.predict_proba(xtest)\n",
    "pred_class = clf.predict(xtest)\n",
    "\n",
    "# Pred and Truth\n",
    "pred_actuals = pd.DataFrame([(pred, act) for pred, act in zip(pred_class, ytest)], columns=['pred', 'true'])\n",
    "print(pred_actuals[:50])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:  0.665959595959596\n",
      "\n",
      "Confusion Matrix: \n",
      " [[65 45]\n",
      " [11 79]]\n",
      "\n",
      "Accuracy Score:  0.72\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.59      0.70       110\n",
      "         1.0       0.64      0.88      0.74        90\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.75      0.73      0.72       200\n",
      "weighted avg       0.76      0.72      0.72       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "truth = pred_actuals.loc[:, 'true']\n",
    "pred = pred_actuals.loc[:, 'pred']\n",
    "scores = np.array(pred_probs)[:, 1]\n",
    "print('AUROC: ', roc_auc_score(truth, scores))\n",
    "print('\\nConfusion Matrix: \\n', confusion_matrix(truth, pred))\n",
    "print('\\nAccuracy Score: ', accuracy_score(truth, pred))\n",
    "print('\\nClassification Report: \\n', classification_report(truth, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(x=None, data=None, cov=None):\n",
    "    \"\"\"Compute the Mahalanobis Distance between each row of x and the data  \n",
    "    x    : vector or matrix of data with, say, p columns.\n",
    "    data : ndarray of the distribution from which Mahalanobis distance of each observation of x is to be computed.\n",
    "    cov  : covariance matrix (p x p) of the distribution. If None, will be computed from data.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(x-np.mean(data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pred  true\n",
      "0      1   1.0\n",
      "1      0   1.0\n",
      "2      1   1.0\n",
      "3      0   0.0\n",
      "4      0   1.0\n",
      "5      0   0.0\n",
      "6      0   1.0\n",
      "7      0   1.0\n",
      "8      1   1.0\n",
      "9      1   0.0\n",
      "10     0   0.0\n",
      "11     0   0.0\n",
      "12     1   0.0\n",
      "13     1   1.0\n",
      "14     1   1.0\n",
      "15     1   1.0\n",
      "16     1   1.0\n",
      "17     1   1.0\n",
      "18     1   1.0\n",
      "19     1   1.0\n",
      "20     0   0.0\n",
      "21     0   0.0\n",
      "22     0   0.0\n",
      "23     0   0.0\n",
      "24     1   0.0\n",
      "25     0   1.0\n",
      "26     1   1.0\n",
      "27     1   0.0\n",
      "28     1   1.0\n",
      "29     1   0.0\n",
      "30     0   0.0\n",
      "31     0   0.0\n",
      "32     0   1.0\n",
      "33     1   0.0\n",
      "34     0   0.0\n",
      "35     1   1.0\n",
      "36     1   1.0\n",
      "37     0   0.0\n",
      "38     1   1.0\n",
      "39     1   1.0\n",
      "40     0   1.0\n",
      "41     1   1.0\n",
      "42     0   0.0\n",
      "43     0   0.0\n",
      "44     0   0.0\n",
      "45     1   1.0\n",
      "46     1   0.0\n",
      "47     0   0.0\n",
      "48     1   1.0\n",
      "49     0   0.0\n"
     ]
    }
   ],
   "source": [
    "class EuclideanBinaryClassifier():\n",
    "    def __init__(self, xtrain, ytrain):\n",
    "        self.xtrain_pos = xtrain[ytrain == 1, :]\n",
    "        self.xtrain_neg = xtrain[ytrain == 0, :]\n",
    "\n",
    "    def predict_proba(self, xtest):\n",
    "        pos_neg_dists = [(p,n) for p, n in zip(euclidean(xtest, self.xtrain_pos), euclidean(xtest, self.xtrain_neg))]\n",
    "        return np.array([(1-n/(p+n), 1-p/(p+n)) for p,n in pos_neg_dists])\n",
    "\n",
    "    def predict(self, xtest):\n",
    "        return np.array([np.argmax(row) for row in self.predict_proba(xtest)])\n",
    "\n",
    "\n",
    "clf = EuclideanBinaryClassifier(xtrain, ytrain)        \n",
    "pred_probs = clf.predict_proba(xtest)\n",
    "pred_class = clf.predict(xtest)\n",
    "\n",
    "# Pred and Truth\n",
    "pred_actuals = pd.DataFrame([(pred, act) for pred, act in zip(pred_class, ytest)], columns=['pred', 'true'])\n",
    "print(pred_actuals[:50])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC:  0.6536363636363637\n",
      "\n",
      "Confusion Matrix: \n",
      " [[70 40]\n",
      " [24 66]]\n",
      "\n",
      "Accuracy Score:  0.68\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.64      0.69       110\n",
      "         1.0       0.62      0.73      0.67        90\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.68      0.68      0.68       200\n",
      "weighted avg       0.69      0.68      0.68       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "truth = pred_actuals.loc[:, 'true']\n",
    "pred = pred_actuals.loc[:, 'pred']\n",
    "scores = np.array(pred_probs)[:, 1]\n",
    "print('AUROC: ', roc_auc_score(truth, scores))\n",
    "print('\\nConfusion Matrix: \\n', confusion_matrix(truth, pred))\n",
    "print('\\nAccuracy Score: ', accuracy_score(truth, pred))\n",
    "print('\\nClassification Report: \\n', classification_report(truth, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
